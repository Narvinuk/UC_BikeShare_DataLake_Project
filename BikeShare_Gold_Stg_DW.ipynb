{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da430d77-7251-4418-a36b-aa312d46e824",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create Date Dimension\n",
    "import pyspark.sql.functions as F \n",
    "min_date=spark.sql(\"select date(min(date)) from silver_payment\").collect()[0][0]\n",
    "#print(min_date)\n",
    "max_date=spark.sql(\"select date(max(date)) from silver_payment\").collect()[0][0]\n",
    "#print(max_date)\n",
    "date_dim = spark.range(0, (max_date - min_date).days + 1) \\\n",
    "    .withColumn(\"date\", F.date_add(F.lit(min_date), F.col(\"id\").cast(\"integer\"))) \\\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(\"date\").cast(\"integer\")) \\\n",
    "    .withColumn(\"day_of_month\", F.dayofmonth(\"date\").cast(\"integer\")) \\\n",
    "    .withColumn(\"day_of_year\", F.dayofyear(\"date\").cast(\"integer\")) \\\n",
    "    .withColumn(\"week_of_year\", F.weekofyear(\"date\").cast(\"integer\")) \\\n",
    "    .withColumn(\"month\", F.month(\"date\").cast(\"integer\")) \\\n",
    "    .withColumn(\"month_name\", F.monthname(\"date\")) \\\n",
    "    .withColumn(\"quarter\", F.quarter(\"date\").cast(\"integer\")) \\\n",
    "    .withColumn(\"year\", F.year(\"date\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edbf7008-056f-441e-9758-709b57b28e4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "date_dim.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"date_dim\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ca053f0-2ead-416a-bc11-1a1cacbdb444",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create Payment Fact table \n",
    "spark.sql('''CREATE TABLE IF NOT EXISTS payment_fact USING DELTA AS \n",
    "          SELECT DISTINCT p.id AS payment_id, dd.id as date_id,amount,rider_id FROM silver_payment p\n",
    "          join date_dim dd on dd.date=p.date\n",
    "          ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52dddbe2-2d93-4566-bca7-c764c741ebcf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+------+--------+\n|payment_id|date_id|amount|rider_id|\n+----------+-------+------+--------+\n|       264|   2038|   9.0|    1011|\n|       516|   2922| 17.99|    1021|\n+----------+-------+------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"Select * from payment_fact limit 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7ae6c88-a41b-4739-bfc9-dd2a3c22f16e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##Create Dim_Rider\n",
    "spark.sql('''CREATE TABLE IF NOT EXISTS dim_rider USING DELTA AS \n",
    "          SELECT DISTINCT * FROM silver_rider''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c0979a2-9cec-44a3-bcd9-f5d8f636e7ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##Create Dim Station\n",
    "spark.sql('''CREATE TABLE IF NOT EXISTS dim_station USING DELTA AS \n",
    "          SELECT DISTINCT  *  FROM silver_station''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f8b67ff-bff0-4fdf-bea7-8b393684eec8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create Dim Ridetype table\n",
    "spark.sql ('''\n",
    "           CREATE TABLE IF NOT EXISTS dim_ride_type\n",
    "USING DELTA\n",
    "AS\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER (ORDER BY rideable_type) AS ride_type_id,\n",
    "  rideable_type\n",
    "FROM\n",
    "  silver_trip\n",
    "GROUP BY\n",
    "  rideable_type\n",
    "  '''\n",
    "           \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ae8116e-6d7f-4215-8378-8dfe63a05ba2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##Create Trip Fact Table\n",
    "spark.sql ('''\n",
    "           CREATE TABLE IF NOT EXISTS trip_fact USING DELTA AS \n",
    "\n",
    "          select t.trip_id ,t.rider_id,t.start_station_id,t.end_station_id,rt.ride_type_id,sdd.id as start_date_id,edd.id as end_date_id, started_at,ended_at,\n",
    "           round(datediff (second, t.started_at, t.ended_at) / 60)  AS trip_duration,\n",
    "            floor (months_between (t.started_at, r.birthday) / 12) as rider_age,r.is_member\n",
    "from silver_trip t\n",
    "join dim_rider r on t.rider_id=r.rider_id\n",
    "join dim_station s on s.station_id=t.start_station_id\n",
    "join dim_station se on se.station_id=t.end_station_id\n",
    "join dim_ride_type rt on rt.rideable_type=t.rideable_type\n",
    "join date_dim sdd on sdd.date=date(t.started_at)\n",
    "join date_dim edd on edd.date=date(t.ended_at)\n",
    "\n",
    "'''\n",
    "           \n",
    "           \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb73c8b2-d300-4288-89cd-c5a4a33a4827",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+----------------+--------------+------------+-------------+-----------+-------------------+-------------------+-------------+---------+---------+\n|         trip_id|rider_id|start_station_id|end_station_id|ride_type_id|start_date_id|end_date_id|         started_at|           ended_at|trip_duration|rider_age|is_member|\n+----------------+--------+----------------+--------------+------------+-------------+-----------+-------------------+-------------------+-------------+---------+---------+\n|222BB8E5059252D7|   34062|    KA1503000064|         13021|           1|         3054|       3054|2021-06-13 09:48:47|2021-06-13 10:07:23|         19.0|       30|     true|\n|1826E16CB5486018|    5342|    TA1306000010|         13021|           1|         3062|       3062|2021-06-21 22:59:13|2021-06-21 23:04:29|          5.0|       26|     true|\n+----------------+--------+----------------+--------------+------------+-------------+-----------+-------------------+-------------------+-------------+---------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql (\"select * from trip_fact limit 2\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BikeShare_Gold_Stg_DW",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
