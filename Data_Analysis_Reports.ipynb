{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35b46146-f0fe-4735-ba5c-2dc6f107eb4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Data Anaylysis how much time is spent per ride Based on the following Factors:\n",
    "\n",
    "- Based on date and time factors such as day of week and time of day\n",
    "- Based on which station is the starting and / or ending station\n",
    "- Based on age of the rider at time of the ride\n",
    "- Based on whether the rider is a member or a casual rider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b9bc047-cb34-4b64-af86-cc834a31517b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+---------+-------------+\n|rider_id|DAY|HOUR|num_rides|minutes_spent|\n+--------+---+----+---------+-------------+\n|    1000|  2|  10|        1|      95640.0|\n|    1000|  2|  17|        1|      53880.0|\n|    1000|  2|  23|        1|      31620.0|\n|    1000|  3|  14|        1|      84660.0|\n|    1000|  6|  19|        1|     170820.0|\n+--------+---+----+---------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Analyze how much time is spent per ride -->  Based on date and time factors such as day of week and time of day\n",
    "\n",
    "rider_stats_by_day_hour=spark.sql (  '''SELECT rider_id, DAY(started_at) as DAY, extract(HOUR FROM started_at) as HOUR, count(*) as num_rides, AVG( DATEDIFF (second, started_at, ended_at)) * 60 as minutes_spent\n",
    "    FROM trip_fact\n",
    "    GROUP by rider_id, DAY(started_at),extract(HOUR FROM started_at)\n",
    "    Order By rider_id,DAY(started_at),extract(HOUR FROM started_at)'''\n",
    "    )\n",
    "rider_stats_by_day_hour.createOrReplaceTempView(\"rider_stats_by_day_hour\")\n",
    "spark.sql (\"Select * from rider_stats_by_day_hour limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f9b24b1-fd5e-473c-b7ea-712cb119da63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------+---------+------------------+\n|start_station_id|end_station_id|trip_count|timespent|          avg_time|\n+----------------+--------------+----------+---------+------------------+\n|             600|           600|       114|  37575.0|329.60526315789474|\n|    TA1308000022|  TA1308000022|      1294|  51259.0|39.612828438948995|\n+----------------+--------------+----------+---------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# How Much Time Spent based on which station is the starting and / or ending station\n",
    "trp_stats_by_stations=spark.sql(\"select start_station_id,end_station_id,count(distinct trip_id) as trip_count,sum(trip_duration) as timespent,avg(trip_duration) as avg_time from trip_fact group by start_station_id,end_station_id\")\n",
    "trp_stats_by_stations.createOrReplaceTempView(\"trp_stats_by_stations\")\n",
    "spark.sql(\"select * from trp_stats_by_stations limit 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed9abd80-6723-486e-a423-fa3b0638e38f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------------+\n|rider_age|trp_count|     avg_timespent|\n+---------+---------+------------------+\n|       75|       45|              51.4|\n|       74|     1768|19.059954751131222|\n+---------+---------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Analyze how much time is spent per ride\n",
    "#Based on age of the rider at time of the ride\n",
    "rider_stats_by_age=spark.sql(\"select rider_age,count(trip_id) as trp_count,avg(trip_duration) as avg_timespent from trip_fact group by rider_age\")\n",
    "\n",
    "rider_stats_by_age.createOrReplaceTempView(\"rider_avg_stats_by_age\")\n",
    "spark.sql(\"select * from rider_avg_stats_by_age ORder By rider_age desc limit 2\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab7f25aa-1814-454c-98f5-812f97f93f10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------------+\n|Member_type|trp_count|total_timespent_hrs|\n+-----------+---------+-------------------+\n|casualrider|   918615|           326582.0|\n|     member|  3666306|          1338940.0|\n+-----------+---------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Based on whether the rider is a member or a casual rider\n",
    "rider_stats_by_member_type=spark.sql(\"select  CASE WHEN is_member=true then 'member' else 'casualrider' end as Member_type,count(trip_id) as trp_count,round(sum(trip_duration)/60 ) as total_timespent_hrs from trip_fact group by  CASE WHEN is_member=true then 'member' else 'casualrider' end \")\n",
    "rider_stats_by_member_type.createOrReplaceTempView(\"rider_stats_by_member_type\")\n",
    "spark.sql(\"select * from rider_stats_by_member_type limit 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc5be842-bd08-480a-b149-388e8b7bb3c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+-----------------+\n|month|year|num_rides|    minutes_spent|\n+-----+----+---------+-----------------+\n|    4|2021|   298207|86494.35231231997|\n|    5|2021|   450994|95410.06802751256|\n+-----+----+---------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# aggregate count of rides and duration by rider, by month\n",
    "rider_stats_month_year = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT  MONTH(started_at) as month, YEAR(started_at) as year, count(*) as num_rides, AVG( DATEDIFF (second, started_at, ended_at)) * 60 as minutes_spent\n",
    "    FROM trip_fact\n",
    "    GROUP by  MONTH(started_at), YEAR(started_at);\n",
    "    \"\"\"\n",
    ")\n",
    "rider_stats_month_year.createOrReplaceTempView(\"rider_stats_month_year\")\n",
    "spark.sql(\"select * from rider_stats_month_year limit 2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f990ddcf-ab3e-476d-982b-07bfdf61d51e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Analyze how much money is spent\n",
    "- Per month, quarter, year\n",
    "- Per member, based on the age of the rider at account start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05598832-a634-495b-b2e5-1a8a463a40a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-------+-----+------------+----------+\n|rider_id|year|quarter|month|Total_Amount|Avg_Amount|\n+--------+----+-------+-----+------------+----------+\n|    1000|2019|      2|    5|         9.0|       9.0|\n|    1000|2019|      2|    6|         9.0|       9.0|\n|    1000|2019|      3|    7|         9.0|       9.0|\n|    1000|2019|      3|    8|         9.0|       9.0|\n|    1000|2019|      3|    9|         9.0|       9.0|\n+--------+----+-------+-----+------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "#how much money is spent Per month, quarter, year Per Rider\n",
    "\n",
    "rider_stats_amount=spark.sql ('''\n",
    "           select r.rider_id,dat.year ,dat.quarter , dat.month ,sum(amount) as Total_Amount, Avg(amount) Avg_Amount\n",
    "           From\n",
    "           dim_rider r join payment_fact p on r.rider_Id=p.rider_Id\n",
    "           join date_dim dat on dat.Id=p.date_id\n",
    "           \n",
    "           Group By r.rider_id,dat.year ,dat.quarter , dat.month\n",
    "           Order By r.rider_id,dat.year ,dat.quarter , dat.month\n",
    "           ''')\n",
    "rider_stats_amount.createOrReplaceTempView(\"rider_stats_amount\")\n",
    "spark.sql(\"select * from rider_stats_amount limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ca70fc5-d53e-4029-9090-aaa6f33d2484",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+------------------+------------------+\n|year|quarter|month|      Total_Amount|        Avg_Amount|\n+----+-------+-----+------------------+------------------+\n|2013|      1|    2|              12.9|              12.9|\n|2013|      1|    3| 817.7499999999999|10.095679012345677|\n|2013|      2|    4|1672.6500000000003|  9.89733727810651|\n|2013|      2|    5|           2716.71|10.290568181818182|\n|2013|      2|    6|3775.2999999999997|10.148655913978494|\n+----+-------+-----+------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "money_spent=spark.sql ('''\n",
    "           select dat.year ,dat.quarter , dat.month ,sum(amount) as Total_Amount, Avg(amount) Avg_Amount\n",
    "           From\n",
    "           dim_rider r join payment_fact p on r.rider_Id=p.rider_Id\n",
    "           join date_dim dat on dat.id=p.date_id\n",
    "           \n",
    "           Group By dat.year ,dat.quarter , dat.month\n",
    "           Order By dat.year ,dat.quarter , dat.month\n",
    "           ''')\n",
    "money_spent.createOrReplaceTempView(\"money_spent\")\n",
    "spark.sql(\"select * from money_spent limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9771a220-ef2c-4c8c-b757-b2ce44a767e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n|rider_age|Total_Amt|\n+---------+---------+\n|       29| 438219.0|\n|       26| 470439.0|\n|       65|   8469.0|\n|       54|  58365.0|\n+---------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "#Per member, based on the age of the rider at account start\n",
    "\n",
    "rider_stats_by_age=spark.sql('''select floor (months_between (account_start_Date, birthday) / 12) as rider_age,sum(p.amount) as Total_Amt   From\n",
    "           dim_rider r join payment_fact p on r.rider_Id=p.rider_Id\n",
    "           where is_member=true\n",
    "          Group By floor (months_between (account_start_Date, birthday) / 12)\n",
    "                     ''')\n",
    "rider_stats_by_age.createOrReplaceTempView(\"rider_stats_by_age\")\n",
    "spark.sql(\"select * from rider_stats_by_age limit 4\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9996cbb-52c0-4c62-af3d-9eb6f93405a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----------+--------------+-----------------+\n|rider_id|Month|trip_count|total_trip_mns|avg_monthly_rides|\n+--------+-----+----------+--------------+-----------------+\n|    1000|    4|         2|          34.0|              2.0|\n|    1000|   11|         3|          58.0|              3.0|\n|    1003|    6|        18|         296.0|             18.0|\n|    1003|   10|        16|         190.0|             16.0|\n+--------+-----+----------+--------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# how many minutes the rider spends on a bike per month\n",
    "spark.sql ('''\n",
    "           select rider_id,MONTH(started_at) as Month,count(distinct trip_id) as trip_count, sum(trip_duration) as total_trip_mns \n",
    "           ,AVG(COUNT(DISTINCT trip_id)) OVER (PARTITION BY rider_id, MONTH(started_at)) AS avg_monthly_rides\n",
    "             from trip_fact \n",
    "           Group by rider_id,MONTH(started_at)\n",
    "           limit 4\n",
    "           ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f72a589-90ec-4652-bda3-0fb6067e10db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----------+--------------+-----------------+\n|rider_id|Month|trip_count|total_trip_mns|avg_monthly_rides|\n+--------+-----+----------+--------------+-----------------+\n|    1000|    4|         2|          34.0|              2.0|\n|    1000|   11|         3|          58.0|              3.0|\n|    1003|    6|        18|         296.0|             18.0|\n|    1003|   10|        16|         190.0|             16.0|\n+--------+-----+----------+--------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# how many minutes the rider spends on a bike per month\n",
    "spark.sql ('''\n",
    "           select t.rider_id,MONTH(started_at) as Month,count(distinct trip_id) as trip_count, sum(trip_duration) as total_trip_mns \n",
    "           ,AVG(COUNT(DISTINCT trip_id)) OVER (PARTITION BY t.rider_id, MONTH(started_at)) AS avg_monthly_rides\n",
    "             from trip_fact t join Dim_rider d on d.rider_id=t.rider_id\n",
    "           Group by t.rider_id,MONTH(started_at)\n",
    "           limit 4\n",
    "           ''').show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Analysis_Reports",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
